# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

---

# ü§ñ AGENT-FIRST DEVELOPMENT

**This project uses the Claude Code Agent System (v2.2.0-alpha) for intelligent orchestration.**

## ‚ö†Ô∏è CRITICAL RULE: Agents Are the DEFAULT

**For ANY multi-step task, research, or strategic work: Launch agents FIRST. Manual implementation is a FALLBACK ONLY.**

### Default Workflow (USE FOR 95% OF TASKS)

1. **Multi-step task or strategic work?** ‚Üí Launch **orchestrator agent** (use Task tool with `subagent_type: "orchestrator"`)
2. **Research needed?** ‚Üí Use `/research <topic>` slash command
3. **Explore codebase?** ‚Üí Use `/scout-explore` slash command
4. **After workflows?** ‚Üí Use `/feedback` to analyze performance
5. **Check progress?** ‚Üí Use `/workflow-status`

**NEVER manually implement unless:**
- Agents explicitly failed after retry AND fallback attempted
- Task is trivial (< 5 lines of code, single file)
- User explicitly requests manual work

### Task ‚Üí Agent Mapping

| User Request | Agent(s) to Use | How to Invoke |
|--------------|-----------------|---------------|
| Research topic/technology | Research Agent | `/research <topic>` |
| Explore/understand codebase | Scout Agent | `/scout-explore` |
| Build feature/implement code | Orchestrator ‚Üí Planner ‚Üí Builder | Launch orchestrator agent |
| Strategic analysis/planning | Orchestrator ‚Üí Research ‚Üí Planner | Launch orchestrator agent |
| Fix bug | Scout (find) ‚Üí Builder (fix) | Launch scout, then builder |
| Check workflow progress | Status command | `/workflow-status` |
| Analyze agent performance | Feedback command | `/feedback` |

## Agent Selection Policy (CRITICAL - Workflow Adherence)

**‚ö†Ô∏è ABSOLUTE RULE: When user approves a multi-phase plan, FOLLOW IT EXACTLY.**

### Decision Tree for Agent vs Direct Tools

**Research Tasks (Market/Competitive/Technical Intelligence):**
- ‚úÖ **Research Agent** ‚Üí Competitive intelligence, vendor docs, market positioning, technical specs from web
- ‚ùå **NOT WebSearch** ‚Üí Research agent provides structured context, not just URLs

**Code Tasks:**
- ‚úÖ **Scout Agent** ‚Üí Codebase exploration and architecture discovery
- ‚úÖ **Planner Agent** ‚Üí Strategic planning and task breakdown
- ‚úÖ **Builder Agent** ‚Üí Code implementation

**Direct Tools (Only When NOT in Approved Workflow):**
- WebSearch ‚Üí Quick fact lookup (dates, versions) when context not needed
- Read/Edit/Write ‚Üí Manual implementation when agents explicitly failed

### Workflow Adherence Rules

1. **If plan specifies an agent, use that agent** (even if direct tools seem faster)
2. **Do NOT substitute direct tools for agents** in approved workflows
3. **Research agent provides structured context**, not just URLs
4. **Document deviations** with `/feedback` immediately if unavoidable
5. **Prefer approved workflow** over perceived efficiency

**Example Scenarios:**

‚úÖ **CORRECT:**
- Plan says "Phase B: Use Research agent" ‚Üí Use Research agent (even if WebSearch seems faster)
- Research agent returns structured context + data
- Workflow logged to database for future reference

‚ùå **WRONG:**
- Plan says "Phase B: Use Research agent" ‚Üí Use WebSearch instead
- Rationale "WebSearch is faster" violates approved plan
- Missing structured context value

**Why This Matters:**
- Approved plans are strategic decisions, not suggestions
- Research agent adds context, not just data retrieval
- Workflow adherence ensures consistent agent utilization
- Deviations undermine planning phase value

### Agent Failure Protocol

If agent doesn't return results in 3 minutes:

1. Check `/workflow-status` to see if agent is still running
2. Query database: `/feedback` to see if agent logged errors
3. Try alternative approach (e.g., manual tools if agent failed)
4. Document failure in next `/feedback` run
5. **Only then** fall back to manual implementation

### Plan Mode = Plan Agent Workflows

When in "plan mode":
- Plan **which agents** to use (Research? Orchestrator? Scout?)
- Plan **agent handoff sequence** (Research ‚Üí Planner ‚Üí Builder)
- Plan **strategic workflow** (what research? what deliverables?)

**NOT**: "Plan what code I'll manually write"

### How to Actually Invoke Agents

**‚ö†Ô∏è CRITICAL**: Slash commands are documentation/prompt templates, NOT agent launchers!

**Method 1: Natural Language (Recommended - Simplest)**
```
"Use the research agent to investigate [topic]"
"Use the orchestrator agent to plan this feature"
"Launch scout agent to explore this codebase"
"Use the planner agent to create implementation roadmap"
```

**Method 2: Task Tool (Explicit Control)**

I will use the Task tool like this:
```python
Task(
    subagent_type="research",
    description="Research topic",
    prompt="Detailed research instructions..."
)
```

**Available Agent Types**:
- `subagent_type="research"` - Deep technical/market research
- `subagent_type="scout"` - Codebase exploration
- `subagent_type="orchestrator"` - Workflow coordination
- `subagent_type="planner"` - Strategic planning
- `subagent_type="builder"` - Implementation

**Method 3: Slash Commands (Guidance Only)**
```bash
/research <topic>    # ‚ö†Ô∏è Just a prompt template, doesn't launch agent
/scout-explore       # ‚ö†Ô∏è Just instructions, use natural language instead
/workflow-status     # Database query (works)
/feedback            # Database analysis (works)
```

**Slash commands expand to instructions for Claude to follow manually**.
To actually invoke agents, use Method 1 (natural language) or Method 2 (Task tool).

### Why This Matters

Without explicit agent-first instructions, Claude defaults to manual implementation even when agents are installed. This section ensures agents are used automatically.

---

## Project Overview

[Add your project-specific information below]
